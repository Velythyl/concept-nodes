# OpenAI GPT-3.5 LLM configuration (faster, cheaper)
_target_: langchain_openai.ChatOpenAI
model: gpt-3.5-turbo
temperature: 0.7
max_tokens: 1024
request_timeout: 60
