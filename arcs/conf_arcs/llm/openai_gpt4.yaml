# OpenAI GPT-4 LLM configuration
_target_: langchain_openai.ChatOpenAI
model: gpt-4o
temperature: 0.7
max_tokens: 1024
request_timeout: 60
